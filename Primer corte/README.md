# Primer corte

## Definiciones en Programaci√≥n Lineal

### Funci√≥n lineal
Una funci√≥n en la cual cada variable se multiplica por una constante y se suman.
 **Ejemplo**: $f(x, y) = 3x + 4y$.

### Inecuaci√≥n lineal
Una inecuaci√≥n que involucra una funci√≥n lineal.
**Ejemplo**: $2x + 3y \leq 5$.

### Sistema de ecuaciones lineales
Conjunto de ecuaciones lineales que deben satisfacerse simult√°neamente. **Ejemplo**: 
$$\begin{aligned}  
2x_1 + 3x_2 &= 6 \\  
x_1 - x_2 &= 2  
\end{aligned}
$$

### PL: Programaci√≥n Lineal
M√©todo de optimizaci√≥n que se utiliza para encontrar la mejor soluci√≥n a un problema matem√°tico lineal, dadas ciertas restricciones.

### Forma General Matricial

Modelo de minimizaci√≥n
$$
\begin{align*}
\text{Minimizar } & z = \mathbf{c} \mathbf{x} \\
\text{Sujeto a:} & \\
&\mathbf{A} \mathbf{x} \leq \mathbf{b} \\
&\mathbf{x} \geq \mathbf{0}
\end{align*}
$$

Modelo de maximizaci√≥n
$$
\begin{align*}
\text{Maximizar } & z = \mathbf{c} \mathbf{x} \\
\text{Sujeto a:} & \\
&\mathbf{A} \mathbf{x} \geq \mathbf{b} \\
&\mathbf{x} \geq \mathbf{0}
\end{align*}
$$

Donde
* $\mathbf{c}$: Vector de coeficientes de la funci√≥n objetivo.
* $\mathbf{x}$: Vector de variables de decisi√≥n.
* $\mathbf{b}$: Vector del RHS las restricciones.
* $\mathbf{A}$: Matriz de coeficientes de las restricciones.

**Referencia**: Bula, Slides de Programaci√≥n Lineal: M√©todo Simplex, 2024, p. 5.

**Componentes del Modelo**

* **$\mathbf{c}$**: Vector de coeficientes de la funci√≥n objetivo.
    
    $$\mathbf{c} = [c_1 \; c_2 \; \cdots \; c_n]$$

* **$\mathbf{x}$**: Vector de variables de decisi√≥n. $\mathbf{x} \in \mathbb{R}^{n \times 1}$. $\mathbf{x} \geq \mathbf{0}$: Todas las variables de decisi√≥n deben ser no negativas, es decir, deben ser iguales o mayores que cero.
    
    $$\mathbf{x} = \begin{pmatrix}  
    x_1 \\  
    x_2 \\  
    \vdots \\  
    x_n  
    \end{pmatrix}$$

* **$\mathbf{b}$**: Vector del lado derecho de las restricciones. $\mathbf{b} \in \mathbb{R}^{m \times 1}$
    
    $$\mathbf{b} = \begin{pmatrix}  
    b_1 \\  
    b_2 \\  
    \vdots \\  
    b_m  
    \end{pmatrix}$$

* **$\mathbf{A}$**: Matriz de coeficientes de las restricciones. $\mathbf{A} \in \mathbb{R}^{m \times n}$
    
    $$\mathbf{A} = \begin{pmatrix}  
    a_{11} & a_{12} & \cdots & a_{1n} \\  
    a_{21} & a_{22} & \cdots & a_{2n} \\  
    \vdots & \vdots & \ddots & \vdots \\  
    a_{m1} & a_{m2} & \cdots & a_{mn}  
    \end{pmatrix}$$

* **$\mathbf{0}$**: Vector de ceros que establece la no negatividad de las variables de decisi√≥n. $\mathbf{0} \in \mathbb{R}^{n \times 1}$
    
    $$\mathbf{0} = \begin{pmatrix}  
    0 \\  
    0 \\  
    \vdots \\  
    0  
    \end{pmatrix}$$

### Suposiciones en Programaci√≥n Lineal

1. **Proporcionalidad**:
    
    * **Descripci√≥n**: La contribuci√≥n de cada variable a la funci√≥n objetivo y a las restricciones es proporcional a su nivel de actividad.
    * **Implicaci√≥n**: Si el coeficiente de $x_j$ en la funci√≥n objetivo es $c_j$, entonces incrementar $x_j$ en una unidad incrementar√° la funci√≥n objetivo en $c_j$. Similarmente, si el coeficiente de $x_j$ en una restricci√≥n es $a_{ij}$, incrementar $x_j$ en una unidad incrementar√° la cantidad del recurso usado en $a_{ij}$.
    * **Ejemplo**: Si producir una unidad de un producto genera $10 de beneficio, entonces producir 10 unidades generar√° $100 de beneficio.
    * **Referencia**: Winston, Operations Research: Applications and Algorithms, 4th ed., p. 53.
2. **Aditividad**:
    
    * **Descripci√≥n**: La contribuci√≥n total de todas las variables a la funci√≥n objetivo y a las restricciones es la suma de sus contribuciones individuales.
    * **Implicaci√≥n**: Las funciones objetivo y las restricciones son lineales, es decir, pueden expresarse como una suma de t√©rminos individuales que involucran variables de decisi√≥n.
    * **Ejemplo**: Si la funci√≥n objetivo es $3x_1 + 5x_2$, el beneficio total es la suma de $3x_1$ (beneficio del primer producto) y $5x_2$ (beneficio del segundo producto).
    * **Referencia**: Winston, Operations Research: Applications and Algorithms, 4th ed., p. 53.

3. **Divisibilidad**:
    
    * **Descripci√≥n**: Las variables de decisi√≥n pueden tomar valores fraccionarios, no solo enteros.
    * **Implicaci√≥n**: Se asume que los productos pueden producirse y los recursos pueden usarse en cualquier cantidad fraccionaria.
    * **Ejemplo**: Si $x_1$ representa el n√∫mero de unidades producidas, $x_1 = 2.5$ es una soluci√≥n v√°lida.

4. **Certeza**:
    
    * **Descripci√≥n**: Todos los coeficientes en la funci√≥n objetivo y en las restricciones son conocidos con certeza y son constantes.
    * **Implicaci√≥n**: No hay incertidumbre en los valores de los par√°metros del modelo. Los coeficientes $c_j$, $a_{ij}$ y $b_i$ son todos conocidos y no cambian.
    * **Ejemplo**: El costo de producci√≥n, la disponibilidad de recursos y los coeficientes de las restricciones son todos valores fijos y conocidos.
    * **Referencia**: Winston, Operations Research: Applications and Algorithms, 4th ed., p. 54.

**Ejemplo de Aplicaci√≥n de Suposiciones en Programaci√≥n Lineal**:

Supongamos que una empresa fabrica dos productos, $P1$ y $P2$. La funci√≥n objetivo es maximizar el beneficio total, y las restricciones son la disponibilidad de tiempo de trabajo y material.

* **Funci√≥n Objetivo**:
    
    $$Z = 30P1 + 40P2$$
    
    donde $30$ es el beneficio por unidad de $P1$ y $40$ es el beneficio por unidad de $P2$.
    
* **Restricciones**:
    
    $$\begin{aligned}  
    2P1 + 1P2 &\leq 100 \quad \text{(Tiempo de trabajo disponible)} \\  
    1P1 + 2P2 &\leq 80 \quad \text{(Material disponible)}  
    \end{aligned}$$
    
* **Suposiciones Aplicadas**:
    
    * **Proporcionalidad**: Si producimos una unidad adicional de $P1$, el beneficio se incrementa en $30 y el tiempo de trabajo usado se incrementa en 2 horas.
    * **Aditividad**: El beneficio total es la suma de los beneficios de $P1$ y $P2$. Similarmente, el uso total de recursos es la suma del uso individual por $P1$ y $P2$.
    * **Divisibilidad**: Podemos producir fracciones de unidades de $P1$ y $P2$, como $P1 = 3.5$ y $P2 = 4.2$.
    * **Certeza**: Los coeficientes $30$, $40$, $2$, $1$, $100$, $1$ y $2$ son todos conocidos y constantes.

### Variable de decisi√≥n
**$x_i$**: Variables que representan las cantidades que se van a determinar para optimizar la funci√≥n objetivo. **Ejemplo**: En un problema de producci√≥n, $x_1$ y $x_2$ pueden representar el n√∫mero de unidades de producto 1 y producto 2 a producir.

### Funci√≥n objetivo
**$z = \mathbf{c}\mathbf{x}$**: es una combinaci√≥n lineal de las variables de decisi√≥n ponderadas por sus respectivos coeficientes. El objetivo es minimizar o mazimizar esta funci√≥n. **Ejemplo**: $Z = 3x_1 + 4x_2$ representa la ganancia total que se desea maximizar.

Tambien se le puede llamar **funci√≥n de costo** o **funci√≥n de beneficio**, seg√∫n si el objetivo es minimizar o maximizar.

**¬øCu√°l es el costo para la base $\mathbf{B}$?**

$$
\begin{aligned}
z = \mathbf{c}\mathbf{x} \quad &= \quad \mathbf{c}_{BV} \mathbf{x}_{BV} + \mathbf{c}_{NBV} \mathbf{x}_{NBV} \\
\quad &= \quad \mathbf{c}_{BV} \left(\mathbf{B}^{-1} \mathbf{b} - \mathbf{B}^{-1} \mathbf{N} \mathbf{x}_{NBV} \right) + \mathbf{c}_{NBV} \mathbf{x}_{NBV} \\
\quad &= \quad \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{b} - \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{N} \mathbf{x}_{NBV} + \mathbf{c}_{NBV} \mathbf{x}_{NBV} \\
\quad &= \quad \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{b} + \left(\mathbf{c}_{NBV} - \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{N}\right) \mathbf{x}_{NBV} \\
\quad &= \quad \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{b} + \left(\mathbf{c}_{NBV} - \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{N}\right) \mathbf{x}_{NBV} + \left(\mathbf{c}_{BV} - \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{B}\right) \mathbf{x}_{BV} \\
\quad &= \quad \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{b} + \left(\mathbf{c} - \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{A}\right) \mathbf{x}
\end{aligned}
$$

Define $\Pi = \mathbf{c}_{BV} \mathbf{B}^{-1}$ como los multiplicadores del m√©todo simplex

$$\mathbf{c}\mathbf{x} = \Pi \mathbf{b} + \left(\mathbf{c} - \Pi \mathbf{A}\right) \mathbf{x}$$

### Restricciones
**$a_{m1}x_1 + a_{m2}x_2 + \ldots + a_{mn}x_n = b_m$**: son un conjunto de ecuaciones o inecuaciones lineales que limitan los valores que pueden tomar las variables de decisi√≥n. **Ejemplo**: $2x_1 + x_2 \leq 100$ puede representar una restricci√≥n de disponibilidad de recursos.

* $\geq$: Las restricciones de mayor o igual en los enunciados se presentan con frases como:
  * "al menos"
  * "como m√≠nimo"
  * "no menos de"
  * "no inferior a"
* $\leq$: Las restricciones de menor o igual en los enunciados se presentan con frases como:
  * "a lo sumo"
  * "como m√°ximo"
  * "no m√°s de"
  * "no superior a"
* $=$: Las restricciones de igualdad en los enunciados se presentan con frases como:
  * "exactamente"
  * "igual a"
  * "debe ser"
  * "se requiere"
* $\geq$ y $\leq$: Las restricciones de rango en los enunciados se presentan con frases como:
  * "entre"
  * "en el rango de"
  * "debe estar entre"
  * "no menos de" y "no m√°s de"

#### Restricciones activas
Son aquellas restricciones que se cumplen como igualdad en la soluci√≥n √≥ptima.

### Coeficientes de Funci√≥n Objetivo ("Costos")
<aside>
üí° La literatura parte de los problemas de minimizaci√≥n, de ah√≠ que se suele utilizar el t√©rmino *costos* para referirse a los coeficientes
</aside>

$c_i$: N√∫meros constantes que multiplican a las **variables de decisi√≥n** en la **funci√≥n objetivo**. Representan los costos o beneficios unitarios asociados con esas variables. Estos coeficientes determinan c√≥mo cada variable afecta el valor total que se est√° maximizando o minimizando. 

- Problemas de Maximizaci√≥n: representan **beneficios**
- Problemas de Minimizaci√≥n: representan **costos**

### Coeficiente Tecnol√≥gico
**$a_i$**, Es el coeficiente que multiplica a la variable de decisi√≥n en una restricci√≥n. Representa la cantidad de recursos que se requieren para producir una unidad de la variable de decisi√≥n. **Ejemplo**: Si $2x_1 + x_2 \leq 100$, entonces $2$ y $1$ son los coeficientes tecnol√≥gicos.
**Referencia**: Winston, Operations Research: Applications and Algorithms, 4th ed., p. 267. y Bula, Slides de Programaci√≥n Lineal: M√©todo Simplex, 2024, p.112.

### Espacio factible
Conjunto de todas las posibles soluciones que satisfacen las restricciones del problema. **Referencia**: Winston, Operations Research: Applications and Algorithms, 4th ed., p. 54.

### Soluci√≥n factible
Cualquier conjunto de valores para las variables de decisi√≥n que satisface todas las restricciones. **Ejemplo**: $x_1 = 2, x_2 = 1$ puede ser una soluci√≥n factible si satisface todas las restricciones del problema.

### Soluci√≥n √≥ptima
Para un problema de **maximizaci√≥n**, una soluci√≥n √≥ptima de un problema de Programaci√≥n Lineal (PL) es un punto en la regi√≥n factible con el mayor valor de la funci√≥n objetivo. De manera similar, para un problema de **minimizaci√≥n**, una soluci√≥n √≥ptima es un punto en la regi√≥n factible con el menor valor de la funci√≥n objetivo (Winston, Operations Research: Applications and Algorithms, 4th ed., p. 54.).

Un PL puede tener una soluci√≥n √≥ptima √∫nica, no tener solucion (*infeasible*), puede tener multiples soluciones (*alternative optimal solutions*), o puede ser ilimitado (*unbounded*). En el caso de que un PL tenga m√∫ltiples soluciones √≥ptimas, todas las soluciones √≥ptimas tendr√°n el mismo valor de la funci√≥n objetivo. (Winston, Operations Research: Applications and Algorithms, 4th ed., p. 113.)

### Restricci√≥n de signo
Condici√≥n que especifica que una variable debe ser no negativa o sin restricci√≥n de signo. **Ejemplo**: $x \geq 0$.

### Forma est√°ndar
<aside>
üí° Necesario para resolver un problema de PL mediante el M√©todo Simplex. 
</aside>
La forma est√°ndar de un problema de programaci√≥n lineal segun Winston es una representaci√≥n donde todas las restricciones son igualdades y todas las variables son no negativas. 

$$
\begin{aligned}  
\text{Maximizar} \quad & z = \mathbf{c}^T \mathbf{x} \\  
\text{sujeto a} \quad & \mathbf{A} \mathbf{x} = \mathbf{b} \\  
& \mathbf{x} \geq 0  
\end{aligned}
$$

$$
\begin{aligned}  
\text{Maximizar} \quad & z = c_1x_1 + c_2x_2 + \ldots + c_nx_n \\  
\text{sujeto a} \quad & a_{11}x_1 + a_{12}x_2 + \ldots + a_{1n}x_n = b_1 \\  
& a_{21}x_1 + a_{22}x_2 + \ldots + a_{2n}x_n = b_2 \\  
& \quad \vdots \\  
& a_{m1}x_1 + a_{m2}x_2 + \ldots + a_{mn}x_n = b_m \\  
& x_i \geq 0 \quad \text{para} \ i = 1, 2, \ldots, n  
\end{aligned}
$$
**Referencia**: Winston, Operations Research: Applications and Algorithms, 4th ed., p. 267.

Un problema de PL est√° en forma est√°ndar si:

1. **Todas las restricciones son igualdades**:
    
    $$\begin{aligned}  
    a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n &= b_1 \\  
    a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n &= b_2 \\  
    &\vdots \\  
    a_{m1}x_1 + a_{m2}x_2 + \cdots + a_{mn}x_n &= b_m  
    \end{aligned}$$
2. **Todas las variables son no negativas**:
    
    $$x_i \geq 0 \quad \text{para} \quad i = 1, 2, \ldots, n$$
3. **Funci√≥n objetivo es de maximizaci√≥n o minimizaci√≥n**:
    
    $$\text{Maximizar} \quad z = c_1x_1 + c_2x_2 + \cdots + c_nx_n$$
    
    o
    
    $$\text{Minimizar} \quad z = c_1x_1 + c_2x_2 + \cdots + c_nx_n$$

Para convertir cualquier problema de PL a su forma est√°ndar:

* **Desigualdades a Igualdades**:
    
    * Para cada restricci√≥n de tipo "‚â§" (menor o igual), a√±ade una variable de holgura $+s$.
    * Para cada restricci√≥n de tipo "‚â•" (mayor o igual), resta una variable de exceso $-e$.

* **Variables no restringidas en signo (urs)**:
    
    * Divide cada variable unrestricted ($x_i$) en la diferencia de dos variables no negativas: $x_i = x_i^+ - x_i^-$ donde $x_i^+ \geq 0$ y $x_i^- \geq 0$.

### Variable de holgura $+s$ (Slack Variables)
Variables que se agregan a las restricciones de un problema de programaci√≥n lineal para convertir las desigualdades tipo **menor o igual** (‚â§) en igualdades. Su significado es la cantidad de recursos no utilizados, "cantidad no utilizada" o "espacio libre", por lo que la variable se **suma** a la restricci√≥n. 

Para una restricci√≥n del tipo $\leq$, $x_1$ y $x_2$ pueden llegar hasta un m√°ximo de $b$. Si $x_1 + x_2$ est√° por debajo de $b$, entonces $s$ representa la "distancia" para llegar a $b$.

**Mnemotecnia**: "Menor o igual a $b_i$: El LHS de la restricci√≥n debe ser $b_i$ o estar por debajo de $b_i$. Si est√° por debajo, $s$ (holgura) es el valor por el cual el LHS est√° por debajo de $b_i$, y se suma al LHS para alcanzar exactamente $b_i$."

**Ejemplo**: Si la restricci√≥n es $a_1x_1 + a_2x_2 \leq b_i$, entonces para alcanzar $b_i$ se suma la holgura: $a_1x_1 + a_2x_2 + s = b_i$.

### Variable de exceso $-e$ (Surplus Variables)
Variables que se agregan a las restricciones de un problema de programaci√≥n lineal para convertir las desigualdades tipo **mayor o igual** "‚â•" en igualdades. Su significado es la cantidad de recursos excedidos o "cantidad por encima", por lo que la variable se **resta** de la restricci√≥n. 

Para una restricci√≥n del tipo $\geq$, $x_1$ y $x_2$ deben ser al menos $b$. Si $x_1 + x_2$ est√° por encima de $b$, $e$ representa el "exceso" por encima de $b$.
    
**Mnemotecnia**: "Mayor o igual a $b_i$: El LHS de la restricci√≥n debe ser $b_i$ o estar por encima de $b_i$. Si se pasa de $b_i$, $e$ (exceso) es el valor por el cual el LHS se pas√≥ de $b_i$, y se resta del LHS para llevarlo a $b_i$."

**Ejemplo**: Si la restricci√≥n es $a_1x_1 + a_2x_2 \geq b_i$, entonces para alcanzar $b_i$ se resta el exceso: $a_1x_1 + a_2x_2 - e = b_i$.

### Forma Can√≥nica
La forma can√≥nica de un problema de programaci√≥n lineal en el contexto de las clases del profesor Bula, una representaci√≥n est√°ndar del problema de optimizaci√≥n, que var√≠a seg√∫n se trate de un problema de minimizaci√≥n o maximizaci√≥n.

**Para el caso de la forma can√≥nica de minimizaci√≥n:**

* La funci√≥n objetivo es minimizada.
* Las restricciones son de tipo *mayor o igual* ($\geq$).
* Las variables de decisi√≥n son no negativas.

$$
\text{Minimizar} \quad z = c_1x_1 + c_2x_2 + \cdots + c_nx_n \\
\text{Sujeto a:} \\
a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n \geq b_1 \\
a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n \geq b_2 \\
\vdots  \\
a_{m1}x_1 + a_{m2}x_2 + \cdots + a_{mn}x_n \geq b_m \\
x_1, x_2, \dots, x_n \geq 0
$$

**Para el caso de la forma can√≥nica de maximizaci√≥n:**

* La funci√≥n objetivo debe ser de maximizaci√≥n.
* Las variables de decisi√≥n no negativas.
* Las restricciones son del tipo *menor o igual* ($\leq$).

$$
\text{Maximizar} \quad z = c_1x_1 + c_2x_2 + \cdots + c_nx_n \\
\text{Sujeto a:} \\
a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n \leq b_1 \\
a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n \leq b_2 \\
\vdots \\
a_{m1}x_1 + a_{m2}x_2 + \cdots + a_{mn}x_n \leq b_m \\
x_1, x_2, \dots, x_n \geq 0
$$

**Cambio de signo en las restricciones**

Si tienes una restricci√≥n del tipo $\sum a_i x_i \leq b$, puedes multiplicar ambos lados de la inecuaci√≥n por $-1$ para convertirla en una forma $\geq$: $-\sum a_i x_i \geq -b$
    
**Memot√©cnia**: *Min max, max min*: En forma can√≥nica el modelo del PL la...
* minimizaci√≥n es mayor.
* maximizaci√≥n es menor.

### Forma Aumentada

es una representaci√≥n extendida de un problema de programaci√≥n lineal que incluye tanto la funci√≥n objetivo como las restricciones en una sola matriz, junto con las variables de decisi√≥n, las variables de holgura, exceso y artificiales, y las restricciones de no negatividad. Esta forma es √∫til para el M√©todo Simplex, ya que facilita la manipulaci√≥n de las restricciones y la funci√≥n objetivo en un √∫nico sistema de ecuaciones.

$$
\begin{aligned}
&\text{Maximizar } z \text{ en:}
\\
&\begin{pmatrix}  
1 & -\mathbf{c}^T & 0 \\  
0 & \mathbf{A} & \mathbf{I}  
\end{pmatrix}  
\begin{pmatrix}  
z \\  
\mathbf{x} \\  
\mathbf{x}_s  
\end{pmatrix}  
 =  
\begin{pmatrix}  
0 \\  
\mathbf{b}  
\end{pmatrix}
\\
& \mathbf{x}, \mathbf{x}_s \geq 0
\end{aligned}
$$

**Referencia**: Bula, Slides de Programaci√≥n Lineal: M√©todo Simplex, 2024, p. 6.

El sistema de ecuaciones en forma aumentada se estructura de la siguiente manera:

* La primera fila de la matriz aumentada representa la funci√≥n objetivo $z$.
    
    $$\begin{pmatrix}  
    1 & -\mathbf{c}^T & 0  
    \end{pmatrix}  
    \begin{pmatrix}  
    z \\  
    \mathbf{x} \\  
    \mathbf{x}_s  
    \end{pmatrix}  
    = 0$$

* Las siguientes filas representan las restricciones del problema con las variables originales $\mathbf{x}$ y las variables de holgura $\mathbf{x}_s$.
    
    $$\begin{pmatrix}  
    0 & \mathbf{A} & \mathbf{I}  
    \end{pmatrix}  
    \begin{pmatrix}  
    z \\  
    \mathbf{x} \\  
    \mathbf{x}_s  
    \end{pmatrix}  
    = \mathbf{b}$$

**Componentes del Modelo**

* **$\mathbf{c}$**: Vector de coeficientes de la funci√≥n objetivo.
    
    $$\mathbf{c} = [c_1 \; c_2 \; \cdots \; c_n]$$

* **$\mathbf{x}$**: Vector de variables de decisi√≥n originales.
    
    $$\mathbf{x} = \begin{pmatrix}  
    x_1 \\  
    x_2 \\  
    \vdots \\  
    x_n  
    \end{pmatrix}$$

* **$\mathbf{x}_s$**: Vector de variables de holgura.
    
    $$\mathbf{x}_s = \begin{pmatrix}  
    s_1 \\  
    s_2 \\  
    \vdots \\  
    s_m  
    \end{pmatrix}$$

* **$\mathbf{A}$**: Matriz de coeficientes de las restricciones.
    
    $$\mathbf{A} = \begin{pmatrix}  
    a_{11} & a_{12} & \cdots & a_{1n} \\  
    a_{21} & a_{22} & \cdots & a_{2n} \\  
    \vdots & \vdots & \ddots & \vdots \\  
    a_{m1} & a_{m2} & \cdots & a_{mn}  
    \end{pmatrix}$$

* **$\mathbf{I}$**: Matriz identidad que representa las variables de holgura.
    
    $$\mathbf{I} = \begin{pmatrix}  
    1 & 0 & \cdots & 0 \\  
    0 & 1 & \cdots & 0 \\  
    \vdots & \vdots & \ddots & \vdots \\  
    0 & 0 & \cdots & 1  
    \end{pmatrix}$$

* **$\mathbf{b}$**: Vector del lado derecho de las restricciones.
    
    $$\mathbf{b} = \begin{pmatrix}  
    b_1 \\  
    b_2 \\  
    \vdots \\  
    b_m  
    \end{pmatrix}$$

* **$\mathbf{z}$**: Variable objetivo que se maximiza.

### M√©todo Simplex
Algoritmo de optimizaci√≥n para resolver problemas de programaci√≥n lineal movi√©ndose de una soluci√≥n b√°sica factible a otra. 

### Tableau
Un tableau es una representaci√≥n tabular utilizada en el m√©todo Simplex para resolver problemas de programaci√≥n lineal. En un tableau, las ecuaciones del problema se organizan en filas y columnas, donde cada fila representa una restricci√≥n y cada columna corresponde a una variable (incluyendo variables de holgura y artificiales). La √∫ltima fila muestra la funci√≥n objetivo, y se utilizan operaciones elementales de fila para iterativamente ajustar el tableau hacia una soluci√≥n √≥ptima. El tableau facilita el seguimiento de las soluciones b√°sicas y las operaciones de pivoteo necesarias en el m√©todo Simplex.

La tabla en forma can√≥nica de un problema de programaci√≥n lineal (PL) con $n$ variables de decisi√≥n y $m$ restricciones se puede escribir de la siguiente manera:

| Row | Ecuaci√≥n en forma can√≥nica                                  | Variable B√°sica |
| --- | ----------------------------------------------------------- | --------------- |
| 0   | $z + \sum_{j=1}^{n} c_j x_j = 0$                            | $z$             |
| 1   | $a_{11} x_1 + a_{12} x_2 + \cdots + a_{1n} x_n + s_1 = b_1$ | $s_1$           |
| 2   | $a_{21} x_1 + a_{22} x_2 + \cdots + a_{2n} x_n + s_2 = b_2$ | $s_2$           |
| ... | ...                                                         | ...             |
| m   | $a_{m1} x_1 + a_{m2} x_2 + \cdots + a_{mn} x_n + s_m = b_m$ | $s_m$           |

Notaciones:

1. **Fila 0 (Funci√≥n Objetivo)**: Representa la funci√≥n objetivo del problema. Los coeficientes $c_j$ corresponden a las variables de decisi√≥n $x_j$. El objetivo es maximizar (o minimizar) $z$.
    
2. **Filas 1 a m (Restricciones)**: Cada fila representa una restricci√≥n del problema original. Las variables $a_{ij}$ son los coeficientes de las variables de decisi√≥n $x_j$ en la restricci√≥n $i$-√©sima. Las variables de holgura $s_i$ se introducen para convertir las desigualdades en igualdades.
    
3. **Variables B√°sicas**: Cada fila tiene una variable b√°sica ($s_i$) con coeficiente 1, y todas las dem√°s variables en esa fila tienen coeficientes 0. Las variables b√°sicas $s_i$ tienen valores en el lado derecho de las ecuaciones $b_i$.

### Tableau √ìptimo
Es una representaci√≥n tabular del problema de programaci√≥n lineal donde se han encontrado los valores √≥ptimos para las variables de decisi√≥n y la funci√≥n objetivo. Este tableau cumple con las siguientes condiciones:

1. **Condici√≥n de optimalidad**: Los **costos reducidos** de todas las variables no b√°sicas (NBV) son no negativos en un problema de maximizaci√≥n (o no positivos en un problema de minimizaci√≥n). Esto indica que no hay m√°s mejor√≠as posibles en la funci√≥n objetivo.

    * En maximizaci√≥n: $\bar{c}_j \geq 0$ para todas las $j$ no b√°sicas.
    * En minimizaci√≥n: $\bar{c}_j \leq 0$ para todas las $j$ no b√°sicas.
  
2. **Condici√≥n de factibilidad**: Las soluciones b√°sicas correspondientes a las restricciones deben ser no negativas. Es decir, todas las variables b√°sicas deben ser mayores o iguales a cero.
    
3. **Valor √≥ptimo**: La celda de la funci√≥n objetivo en el tableau √≥ptimo proporciona el valor m√°ximo o m√≠nimo alcanzado por la funci√≥n objetivo.

### Prueba de optimalidad

### Soluci√≥n actual
Una soluci√≥n actual es aquella que se ha derivado utilizando las variables b√°sicas y no b√°sicas, y puede no ser √≥ptima.

### Soluci√≥n b√°sica (BS)

La **soluci√≥n b√°sica (BS)** es simplemente la soluci√≥n obtenida al fijar las variables no b√°sicas ($\mathbf{x}_{NBV}$) en cero y resolver el sistema resultante para las variables b√°sicas ($\mathbf{x}_{BV}$). Esta soluci√≥n no necesariamente cumple con las restricciones de no negatividad de las variables b√°sicas, por lo que puede incluir valores negativos.

### Soluci√≥n b√°sica factible (BFS)
Soluci√≥n b√°sica que tambi√©n satisface todas las restricciones del problema PL. 

Se parte del sistema de ecuaciones 
$$
\mathbf{A}\mathbf{x} = \mathbf{b}
$$

La ecuaci√≥n se descompone como: 
$$
\mathbf{B}\mathbf{x}_{BV} + \mathbf{N}\mathbf{x}_{NBV} = \mathbf{b}
$$
Donde,
* $\mathbf{B}\mathbf{x}_{BV}$ representa la contribuci√≥n de las variables b√°sicas.
* $\mathbf{N}\mathbf{x}_{NBV}$ representa la contribuci√≥n de las variables no b√°sicas.

**Soluci√≥n de las variables b√°sicas:**

Se reescribe la ecuaci√≥n como: 
$$
\mathbf{B}\mathbf{x}_{BV} = \mathbf{b} - \mathbf{N}\mathbf{x}_{NBV}$$
Al resolver para $\mathbf{x}_{BV}$: 
$$
\mathbf{x}_{BV} = \mathbf{B}^{-1} \mathbf{b} - \mathbf{B}^{-1} \mathbf{N} \mathbf{x}_{NBV}
$$
Aqu√≠ muestra c√≥mo las variables b√°sicas ($\mathbf{x}_{BV}$) se calculan en funci√≥n de las variables no b√°sicas ($\mathbf{x}_{NBV}$).

**Condici√≥n de factibilidad:**
    
La soluci√≥n es factible (BFS) si $\mathbf{b}' \geq 0$, es decir, si todas las variables b√°sicas $\mathbf{x}_{BV}$ son no negativas.

1. **$\mathbf{x}_{NBV} = 0$**:
    
    * En la BFS, todas las **variables no b√°sicas** ($\mathbf{x}_{NBV}$) son iguales a cero. Estas variables corresponden a las columnas de la matriz $\mathbf{A}$ que no est√°n incluidas en la base $\mathbf{B}$.
2. **$\mathbf{x}_{BV} \geq 0$**:
    
    * Los valores de las **variables b√°sicas** ($\mathbf{x}_{BV}$), que se obtienen resolviendo el sistema $\mathbf{B}\mathbf{x}_{BV} = \mathbf{b}$, son **no negativos**. Para que la soluci√≥n sea factible, es necesario que todos los valores de $\mathbf{x}_{BV}$ sean no negativos.

**Notaci√≥n**: 
* $\bar{\mathbf{x}} = [\bar{\mathbf{x}}_{BV}, \bar{\mathbf{x}}_{NBV}]$ [Winston]
* ${\mathbf{x}^*} = [{\mathbf{x}^*}_{BV}, {\mathbf{x}^*}_{NBV}]$ [Bula]

### Multiplicador Simplex
**¬øCu√°l es el costo para la base $\mathbf{B}$?**

$$
\begin{aligned}
z = \mathbf{c}\mathbf{x} \quad &= \quad \mathbf{c}_{BV} \mathbf{x}_{BV} + \mathbf{c}_{NBV} \mathbf{x}_{NBV} \\
\quad &= \quad \mathbf{c}_{BV} \left(\mathbf{B}^{-1} \mathbf{b} - \mathbf{B}^{-1} \mathbf{N} \mathbf{x}_{NBV} \right) + \mathbf{c}_{NBV} \mathbf{x}_{NBV} \\
\quad &= \quad \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{b} - \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{N} \mathbf{x}_{NBV} + \mathbf{c}_{NBV} \mathbf{x}_{NBV} \\
\quad &= \quad \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{b} + \left(\mathbf{c}_{NBV} - \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{N}\right) \mathbf{x}_{NBV} \\
\quad &= \quad \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{b} + \left(\mathbf{c}_{NBV} - \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{N}\right) \mathbf{x}_{NBV} + \left(\mathbf{c}_{BV} - \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{B}\right) \mathbf{x}_{BV} \\
\quad &= \quad \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{b} + \left(\mathbf{c} - \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{A}\right) \mathbf{x}
\end{aligned}
$$

Define $\Pi = \mathbf{c}_{BV} \mathbf{B}^{-1}$ como los multiplicadores del m√©todo simplex

### Soluci√≥n B√°sica Factible Inicial (IBFS):
Se refiere a la primera soluci√≥n b√°sica factible utilizada como punto de partida para el m√©todo simplex. La SBFI se puede obtener de diferentes maneras dependiendo de la forma del problema:

1. Problemas con Restricciones de Igualdad.
2. Problemas con Restricciones de Desigualdad
3. M√©todo de las Dos Fases

### Variables b√°sicas (BV)
$BV = \{BV_1, BV_2, \ldots, BV_m\}$ es un conjunto de $m$ variables (donde $m$ es el n√∫mero de restricciones) que forman una soluci√≥n b√°sica factible (BFS) del sistema de ecuaciones asociado. Una varaible BV no est√° fijada en cero en la soluci√≥n b√°sica factible (BFS).

### Vector BV
$x_{b}$ (en la literatuva del profesor Bula) o $x_{BV}$ es el vector columna $n \times 1$ $[x_{BV1}, x_{BV2}, \ldots, x_{BVn}]$: son los valores variables b√°sicas VB en la soluci√≥n b√°sica (BS).

### Coeficientes BV
$\mathbf{c}_{BV}$ es el vector fila $1 \times m$ $[\mathbf{c}_{BV1}, \mathbf{c}_{BV2}, \ldots, \mathbf{c}_{BVn}]$: son los coeficientes de la funci√≥n objetivo para las variables b√°sicas VB del tableau √≥ptimo.

### Variables no b√°sicas (NBV)
$NBV = \{NBV_1, NBV_2, \ldots, NBV_{n-m}\}$ es un conjunto de $n-m$ variables que no forman parte de la soluci√≥n b√°sica factible (BFS) del sistema de ecuaciones asociado. Una varaible NBV est√° fijada en cero en la soluci√≥n b√°sica factible (BFS).

### Vector NBV
$x_{n}$ (en la literatuva del profesor Bula) $x_{NBV}$ es el vector columna $n \times 1$ $[x_{NBV1}, x_{NBV2}, \ldots, x_{NBVn}]$: son los valores de las variables no b√°sicas NBV en la soluci√≥n b√°sica (BS).

### Coeficientes NBV
$\mathbf{c}_{NBV}$ es el vector fila $1 \times (n - m)$ cuyos elementos son los coeficientes de las variables no b√°sicas (en el orden de NBV).

### Matriz b√°sica o Base
Puesto que en $\mathbf{A}$ corresponde una columna para cada variable de decisi√≥n $x_i$, la matriz $\mathbf{A_B}$ (en la literatuva del profesor Bula) o  $\mathbf{B}$ ($m \times m$) es una submatriz de $\mathbf{A}$, donde la columna $j$ de $\mathbf{B}$ es la columna de $\mathbf{A}$ correspondiente a la variable b√°sica $x_{BV_j}$. En otras palabras, $\mathbf{B}$ es una matriz cuadrada formada por las columnas de $\mathbf{A}$ correspondientes a las variables b√°sicas BV.

Una variable **entra en la base** durante el proceso del m√©todo simplex cuando se selecciona una variable no b√°sica (NBV) $x_j$ para que aumente desde cero y se convierta en una variable b√°sica (BV). Esto implica que una de las variables b√°sicas actuales debe salir de la base para mantener el n√∫mero de variables b√°sicas igual al n√∫mero de restricciones.

### Matriz no b√°sica
La matriz $\mathbf{A_N}$ (en la literatuva del profesor Bula) o $\mathbf{N}$ ($m \times (n - m)$) es una submatriz de $\mathbf{A}$, donde la columna $j$ de $\mathbf{N}$ es la columna de $\mathbf{A}$ correspondiente a la variable no b√°sica $x_{NBV_j}$. En otras palabras, $\mathbf{N}$ es una matriz formada por las columnas de $\mathbf{A}$ correspondientes a las variables no b√°sicas NBV.

### Partici√≥n de A
$$\mathbf{A} = [\mathbf{B} \quad \mathbf{N}]$$
Donde $\mathbf{B}$ es una matriz $m \times m$ formada por las columnas de $\mathbf{A}$ correspondientes a las variables b√°sicas (BV), y $\mathbf{N}$ es una matriz $m \times (n-m)$ formada por las columnas correspondientes a las variables no b√°sicas (NBV).

### Inversa de la Base
Expresando las restricciones en cualquier tableau en t√©rminos de $B^{-1}$ y el PL original

**Funci√≥n Objetivo:**

$$z = \mathbf{c}_{BV} \mathbf{x}_{BV} + \mathbf{c}_{NBV} \mathbf{x}_{NBV}$$

**Restricciones:**

$$\mathbf{B} \mathbf{x}_{BV} + \mathbf{N} \mathbf{x}_{NBV} = \mathbf{b}$$

**No negatividad:**

$$\mathbf{x}_{BV}, \mathbf{x}_{NBV} \geq 0$$

Multiplicando las restricciones por $\mathbf{B}^{-1}$, obtenemos:

$$
\mathbf{B}^{-1} \mathbf{B} \mathbf{x}_{BV} + \mathbf{B}^{-1} \mathbf{N} \mathbf{x}_{NBV} = \mathbf{B}^{-1} \mathbf{b}
$$

o

$$
\mathbf{x}_{BV} + \mathbf{B}^{-1} \mathbf{N} \mathbf{x}_{NBV} = \mathbf{B}^{-1} \mathbf{b}
$$

En donde $\mathbf{BV}_i$ ocurre con un coeficiente de 1 en la i-√©sima restricci√≥n y un coeficiente de cero en cada otra restricci√≥n. As√≠, $\mathbf{BV}$ es el conjunto de variables b√°sicas, y proporciona las restricciones para el tableau √≥ptimo.

Podemos obtener una soluci√≥n b√°sica factible (BFS) a partir de la inversa de la base $\mathbf{B}^{-1}$ y el vector $\mathbf{b}$. Reorganizamos la ecuaci√≥n para resolver $\mathbf{x}_{BV}$ en t√©rminos de $\mathbf{x}_{NBV}$.

$$
\mathbf{x}_{BV} = \mathbf{B}^{-1} \mathbf{b} - \mathbf{B}^{-1} \mathbf{N} \mathbf{x}_{NBV}
$$

La soluci√≥n $\mathbf{x}_{BV}$ es factible si $\mathbf{b}' \geq 0$, donde $\mathbf{b}' = \mathbf{B}^{-1} \mathbf{b}$.
   
$$\mathbf{B} \mathbf{x}_{BV} = \mathbf{b}' - \mathbf{N}' \mathbf{x}_{NBV}$$

Si $\mathbf{b}' \geq 0$, la soluci√≥n es una BFS.

**Determinando la Fila 0 del Tableau √ìptimo en T√©rminos del PL Inicial**

Para comenzar, multiplicamos las restricciones (expresadas en la forma $\mathbf{B}\mathbf{x}_{BV} + \mathbf{N}\mathbf{x}_{NBV} = \mathbf{b}$) por el vector $\mathbf{c}_{BV}\mathbf{B}^{-1}$:

$$
\begin{aligned}
\mathbf{B}\mathbf{x}_{BV} + \mathbf{N}\mathbf{x}_{NBV} &= \mathbf{b}\\
\mathbf{c}_{BV}\mathbf{B}^{-1}\mathbf{B}\mathbf{x}_{BV} + \mathbf{c}_{BV}\mathbf{B}^{-1}\mathbf{N}\mathbf{x}_{NBV} &= \mathbf{c}_{BV}\mathbf{B}^{-1}\mathbf{b}\\
\mathbf{c}_{BV}\mathbf{x}_{BV} + \mathbf{c}_{BV}\mathbf{B}^{-1}\mathbf{N}\mathbf{x}_{NBV} &= \mathbf{c}_{BV}\mathbf{B}^{-1}\mathbf{b} \\
\mathbf{c}_{BV}\mathbf{x}_{BV} + \mathbf{c}_{BV}\mathbf{B}^{-1}\mathbf{N}\mathbf{x}_{NBV} - \mathbf{c}_{BV}\mathbf{B}^{-1}\mathbf{b} &= 0 
\end{aligned}

$$

y reescribimos la funci√≥n objetivo original, $z = \mathbf{c}_{BV}\mathbf{x}_{BV}$, sustituyendo $\mathbf{x}_{BV} = \mathbf{B}^{-1} \mathbf{b} - \mathbf{B}^{-1} \mathbf{N} \mathbf{x}_{NBV}$, como

$$
\begin{aligned}
z &= \mathbf{c}_{BV}\mathbf{x}_{BV} \\
z &= \mathbf{c}_{BV}(\mathbf{B}^{-1}\mathbf{b} - \mathbf{B}^{-1}\mathbf{N}\mathbf{x}_{NBV}) \\
z &= \mathbf{c}_{BV}\mathbf{B}^{-1}\mathbf{b} - \mathbf{c}_{BV}\mathbf{B}^{-1}\mathbf{N}\mathbf{x}_{NBV} = 0 \\

z - \mathbf{c}_{BV}\mathbf{B}^{-1}\mathbf{b} + \mathbf{c}_{BV}\mathbf{B}^{-1}\mathbf{N}\mathbf{x}_{NBV} &= 0
\end{aligned}
$$

podemos eliminar las variables b√°sicas del tableau √≥ptimo y obtener su fila 0:

$$
\begin{aligned}

z &=\mathbf{c}_{BV}\mathbf{B}^{-1}\mathbf{b} - \mathbf{c}_{BV}\mathbf{B}^{-1}\mathbf{N}\mathbf{x}_{NBV} + \mathbf{c}_{NBV}\mathbf{x}_{NBV}
\\
z + \mathbf{c}_{BV}\mathbf{B}^{-1}\mathbf{N}\mathbf{x}_{NBV} - \mathbf{c}_{NBV}\mathbf{x}_{NBV} &= \mathbf{c}_{BV}\mathbf{B}^{-1}\mathbf{b}
\\
z + (\mathbf{c}_{BV}\mathbf{B}^{-1}\mathbf{N} - \mathbf{c}_{NBV})\mathbf{x}_{NBV} &= \mathbf{c}_{BV}\mathbf{B}^{-1}\mathbf{b}
\end{aligned}
$$

el coeficiente de $x_j$ en la fila 0 es

$$\mathbf{c}_{BV}\mathbf{B}^{-1} (\text{columna de } \mathbf{N} \text{ para } x_j) - (\text{coeficiente de } x_j \text{ en } \mathbf{c}_{NBV}) = \mathbf{c}_{BV}\mathbf{B}^{-1}\mathbf{a}_j - c_j$$

y el lado derecho de la fila 0 es $\mathbf{c}_{BV}\mathbf{B}^{-1}\mathbf{b}$.

Para ayudar a resumir la discusi√≥n anterior, dejemos que $\tilde{c}_j$ sea el coeficiente de $x_j$ en la fila 0 del tableau √≥ptimo. Entonces hemos mostrado que

$$\tilde{c}_j = \mathbf{c}_{BV}\mathbf{B}^{-1}\mathbf{a}_j - c_j$$

y

$$\text{Lado derecho de la fila 0 del tableau √≥ptimo} = \mathbf{c}_{BV}\mathbf{B}^{-1}\mathbf{b}$$

### Multiplicador Simplex $\Pi$, Precio Sombra de la i-√©sima restricci√≥n o Valor Dual
Valor que indica cu√°nto cambiar√≠a la funci√≥n objetivo por una unidad adicional del RHS de una restricci√≥n. 

> El **precio sombra** de la i-√©sima restricci√≥n es la cantidad en la que el valor √≥ptimo de $z$ mejora (aumenta en un problema de maximizaci√≥n y disminuye en un problema de minimizaci√≥n) si incrementamos $b_i$ en 1 (de $b_i$ a $b_i + 1$).

**Ejemplo**: Si el precio sombra de una restricci√≥n es 2, agregar una unidad al RHS de esa restricci√≥n incrementar√° la funci√≥n objetivo en 2 unidades.

**¬øCu√°l es el costo para la base $\mathbf{B}$?**

$$
\begin{aligned}
z = \mathbf{c}\mathbf{x} &= \quad \mathbf{c}_{BV} \mathbf{x}_{BV} + \mathbf{c}_{NBV} \mathbf{x}_{NBV} \\
\quad &= \quad \mathbf{c}_{BV} \left(\mathbf{B}^{-1} \mathbf{b} - \mathbf{B}^{-1} \mathbf{N} \mathbf{x}_{NBV} \right) + \mathbf{c}_{NBV} \mathbf{x}_{NBV} \\
\quad &= \quad \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{b} - \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{N} \mathbf{x}_{NBV} + \mathbf{c}_{NBV} \mathbf{x}_{NBV} \\
\quad &= \quad \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{b} + \left(\mathbf{c}_{NBV} - \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{N}\right) \mathbf{x}_{NBV} \\
\quad &= \quad \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{b} + \left(\mathbf{c}_{NBV} - \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{N}\right) \mathbf{x}_{NBV} + \left(\mathbf{c}_{BV} - \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{B}\right) \mathbf{x}_{BV} \\
\quad &= \quad \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{b} + \left(\mathbf{c} - \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{A}\right) \mathbf{x}
\end{aligned}
$$

Define $\Pi = \mathbf{c}_{BV} \mathbf{B}^{-1}$ como los multiplicadores del m√©todo **simplex**

Probar que una base es √≥ptima, es verificar que
$$
\begin{aligned}
z = \mathbf{c}\mathbf{x} &= \quad \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{b} + \left(\mathbf{c} - \mathbf{c}_{BV} \mathbf{B}^{-1} \mathbf{A}\right) \mathbf{x} \\
z = \mathbf{c}\mathbf{x} &= \quad \Pi \mathbf{b} + \left(\mathbf{c} - \Pi \mathbf{A}\right) \mathbf{x}
\end{aligned}
$$

### Dualidad
Dado un primal
$$
\begin{aligned}
&\text{max} \quad z = \mathbf{c}^T \mathbf{x} \\
&\text{s. a.} \\
&\mathbf{A}\mathbf{x} \leq \mathbf{b} \\
&\mathbf{x} \geq 0
\end{aligned}
$$

Donde
* $\mathbf{c}$ es un vector de costos de las variables de decisi√≥n de dimensi√≥n $n$.
* $\mathbf{x}$ es un vector de variables de decisi√≥n de dimensi√≥n $n$.
* $\bar{\mathbf{x}}$ es vector de variables de la BFS.
* $\mathbf{A}$ es una matriz de restricciones de dimensi√≥n $m \times n$.
* $\mathbf{b}$ es un vector de RHS de las restricciones de dimension $m$.

El dual es
$$
\begin{aligned}
&\text{min} \quad w = \mathbf{b}^T \mathbf{y} \\
&\text{s. a.} \\
&\mathbf{A}^T\mathbf{y} \geq \mathbf{c} \\
&\mathbf{y} \geq 0
\end{aligned}
$$

Donde
* $\mathbf{y}$ es un vector de variables duales de dimensi√≥n $m$.
* $\bar{\mathbf{y}}$ es vector de variables de la BFS.
* $\mathbf{b}$ ahora es un vector de restricciones.
* $\mathbf{A}^T$ es la transpuesta de la matriz de restricciones.
* $\mathbf{c}$ es ahora el RHS de las restricciones de dimensi√≥n $n$.

**Propiedades de la dualidad**

### Costo marginal (Marginal Cost) de NBV
Cambio en la funci√≥n objetivo por una unidad adicional de una variable de decisi√≥n. **Ejemplo**: Si el costo marginal de $x_1$ es 3, entonces incrementar $x_1$ en una unidad incrementar√° la funci√≥n objetivo en 3.

### Costo Reducido (Reduced Cost) de NBV
Diferencia entre el costo marginal de una variable y su contribuci√≥n a la funci√≥n objetivo en una soluci√≥n b√°sica factible. 

Indica cu√°nto cambiar√≠a la funci√≥n objetivo si se incrementa una unidad de una variable no b√°sica (NBV).

El costo reducido de una variable no b√°sica (NBV) en una soluci√≥n b√°sica factible (BFS) es la cantidad en que el coeficiente de la variable en la funci√≥n objetivo tendr√≠a que mejorar (aumentar en maximizaci√≥n o disminuir en minimizaci√≥n) antes de que esa variable entre en la **base**.

En t√©rminos m√°s simples, el costo reducido indica cu√°nto afectar√≠a el valor de la funci√≥n objetivo si aumentamos una variable no b√°sica desde cero.

- En problemas de **maximizaci√≥n**, un costo reducido positivo sugiere que aumentar esa variable aumentar√≠a el valor de la funci√≥n objetivo.
- En problemas de **minimizaci√≥n**, un costo reducido negativo sugiere que aumentar esa variable disminuir√≠a el valor de la funci√≥n objetivo.

$$
\bar{c}_j = \mathbf{c}_{BV} \mathbf{A_B}^{-1} \mathbf{a}_j - c_j
$$


### Holgura
Diferencia entre el lado izquierdo y derecho de una restricci√≥n cuando se eval√∫a en la soluci√≥n √≥ptima. **Ejemplo**: Si la restricci√≥n es $2x + 3y \leq 10$ y en la soluci√≥n √≥ptima $2x + 3y = 8$, la holgura es 2.

## Teoremas y Lemas Fundamentales en Programaci√≥n Lineal

### Lema 1 Dualidad D√©bil (Weak Duality)

Sea

$$\mathbf{x} = \begin{bmatrix}  
x_1 \\  
x_2 \\  
\vdots \\  
x_n  
\end{bmatrix}$$

cualquier soluci√≥n factible para el problema primal y

$$\mathbf{y} = [y_1 \; y_2 \; \cdots \; y_m]$$

cualquier soluci√≥n factible para el problema dual. Entonces (valor z para $\mathbf{x}$) $\leq$ (valor w para $\mathbf{y}$).

**Referencia**: Winston, Operations Research: Applications and Algorithms, 4th ed., p. 305.

### Lema 2

Sea

$$\bar{\mathbf{x}} = \begin{bmatrix}  
\bar{x}_1 \\  
\bar{x}_2 \\  
\vdots \\  
\bar{x}_n  
\end{bmatrix}$$

cualquier soluci√≥n factible para el problema primal y

$$\mathbf{y} = [y_1 \; y_2 \; \cdots \; y_m]$$

cualquier soluci√≥n factible para el problema dual. Si $\mathbf{c} \bar{\mathbf{x}} = \mathbf{y} \mathbf{b}$, entonces $\bar{\mathbf{x}}$ es √≥ptima para el problema primal y $\mathbf{y}$ es √≥ptima para el problema dual.

**Referencia**: Winston, Operations Research: Applications and Algorithms, 4th ed., p. 307.

### Lema 3

> Si el primal es ilimitado, entonces el problema dual es infactible.

**Referencia**: Winston, Operations Research: Applications and Algorithms, 4th ed., p. 307.

### Lema 4

> Si el dual es ilimitado, entonces el primal es infactible.

**Referencia**: Winston, Operations Research: Applications and Algorithms, 4th ed., p. 307.

### Lemma 5

Si el problema primal tiene una soluci√≥n √≥ptima finita, entonces el problema dual tambi√©n tiene una soluci√≥n √≥ptima finita, y sus valores √≥ptimos son iguales.

**Referencia**: Winston, Operations Research: Applications and Algorithms, 4th ed., p. 299.

### Lemma 6

Si el problema dual tiene una soluci√≥n √≥ptima finita, entonces el problema primal tambi√©n tiene una soluci√≥n √≥ptima finita, y sus valores √≥ptimos son iguales.

**Referencia**: Winston, Operations Research: Applications and Algorithms, 4th ed., p. 299.

### Teorema de la Dualidad
> Supongamos que $BV$ es una base √≥ptima para el primal. Entonces $\mathbf{c}_{BV} \mathbf{B}^{-1}$ es una soluci√≥n √≥ptima para el dual. Adem√°s, $\bar{z} = \bar{w}$.

**Referencia**: Winston, Operations Research: Applications and Algorithms, 4th ed., p. 308.

Donde,
* **$\mathbf{c}_{BV}$**: Es el vector de costos asociado con las variables b√°sicas (BV) en el problema primal.
* **$\mathbf{B}^{-1}$**: Es la inversa de la matriz de restricciones asociada con las variables b√°sicas en el problema primal.
* **$\bar{z}$**: Es el valor √≥ptimo de la funci√≥n objetivo del problema primal.
* **$\bar{w}$**: Es el valor √≥ptimo de la funci√≥n objetivo del problema dual.


El teorema de la dualidad establece que si $\mathbf{c}_{BV}$ es el vector de costos asociado con las variables b√°sicas en el problema primal y $\mathbf{B}$ es la matriz de restricciones asociada con las variables b√°sicas en el problema primal, entonces $\mathbf{c}_{BV} \mathbf{B}^{-1}$ proporciona una soluci√≥n √≥ptima para el problema dual. Esto implica que los costos de las variables b√°sicas en el primal se pueden transformar a trav√©s de la inversa de la matriz de restricciones para encontrar los valores duales correspondientes.

**Resumen**: Si un problema de programaci√≥n lineal (primal) tiene una soluci√≥n √≥ptima, entonces el problema dual tambi√©n tiene una soluci√≥n √≥ptima, y los valores √≥ptimos de ambos problemas son iguales.
    
**Implicaci√≥n**: Permite verificar la optimalidad y proporciona informaci√≥n sobre los precios sombra.

### Teorema de Holgura Complementaria

> $$y_i (b_i - \mathbf{a}_i \mathbf{x}) = 0 \quad \text{y} \quad x_j (c_j - \mathbf{a}_j^T \mathbf{y}) = 0$$
> Para cada par de variables duales y primales asociadas, al menos una de ellas debe ser cero en la soluci√≥n √≥ptima.
   
**Implicaci√≥n**: Si una restricci√≥n tiene holgura en la soluci√≥n √≥ptima, entonces su precio sombra es cero, y viceversa.

**Referencia**: Winston, Operations Research: Applications and Algorithms, 4th ed., p. 301.

El **Teorema de Complementariedad** establece que, para cada par de problemas primal y dual, si $\mathbf{x}^*$ es una soluci√≥n √≥ptima para el primal y $\mathbf{y}^*$ es una soluci√≥n √≥ptima para el dual, entonces:

$$y_j^* (\mathbf{a}_j^T \mathbf{x}^* - b_j) = 0 \quad \text{para cada } j \text{ en el dual}$$

y

$$x_i^* (c_i - \mathbf{a}_i^T \mathbf{y}^*) = 0 \quad \text{para cada } i \text{ en el primal}$$

Este teorema nos dice que para cada restricci√≥n en el problema primal, el valor dual correspondiente ser√° cero a menos que la restricci√≥n sea activa (es decir, que se cumpla con igualdad). Similarmente, para cada variable primal, el valor de la variable ser√° cero a menos que la desigualdad correspondiente en el dual sea activa.

**Memotecnia**: $y_j^* del dual ser√° 0 si la restricci√≥n $j$ del primal no es activa (no se cumple en igualdad).

### Teorema de la Dualidad Fuerte

$$Z_{\text{primal}} = W_{\text{dual}}$$

Si el problema primal tiene una soluci√≥n √≥ptima finita, entonces el problema dual tambi√©n tiene una soluci√≥n √≥ptima finita, y sus valores √≥ptimos son iguales.
    
**Implicaci√≥n**: Refuerza la validez del Teorema Fundamental de la Dualidad.

**Referencia**: Winston, Operations Research: Applications and Algorithms, 4th ed., p. 299.

### Teorema de la Dualidad D√©bil

$$W_{\text{dual}} \leq Z_{\text{primal}}$$

Si $\mathbf{x}$ es una soluci√≥n factible para el problema primal y $\mathbf{y}$ es una soluci√≥n factible para el problema dual, entonces el valor de la funci√≥n objetivo del dual es siempre menor o igual al valor de la funci√≥n objetivo del primal.
    
**Implicaci√≥n**: Establece una cota inferior para el valor √≥ptimo del problema primal y una cota superior para el valor √≥ptimo del problema dual.

**Referencia**: Winston, Operations Research: Applications and Algorithms, 4th ed., p. 299.

### Teorema de Factibilidad Primal

Si existe una soluci√≥n factible para el problema primal, entonces existe una soluci√≥n factible para el problema dual.

**Implicaci√≥n**: Garantiza que la b√∫squeda de soluciones en el problema dual es v√°lida siempre que haya soluciones en el problema primal.

**Referencia**: Winston, Operations Research: Applications and Algorithms, 4th ed., p. 307.

### Teorema de Factibilidad Dual

Si existe una soluci√≥n factible para el problema dual, entonces existe una soluci√≥n factible para el problema primal.

**Implicaci√≥n**: Similar al teorema anterior, pero en el sentido inverso.

**Referencia**: Winston, Operations Research: Applications and Algorithms, 4th ed., p. 307.

### Teorema de la Optimalidad del Simplex

$$\bar{c}_j \geq 0 \quad \forall j \quad \text{(para maximizaci√≥n)}$$ 
$$\bar{c}_j \leq 0 \quad \forall j \quad \text{(para minimizaci√≥n)}$$

Una soluci√≥n b√°sica factible es √≥ptima si y solo si todos los costos reducidos son no negativos en un problema de maximizaci√≥n (o no positivos en un problema de minimizaci√≥n).

**Implicaci√≥n**: Permite verificar la optimalidad de una soluci√≥n b√°sica factible en el m√©todo Simplex.

**Referencia**: Winston, Operations Research: Applications and Algorithms, 4th ed., p. 146.

### Teorema de la Degeneraci√≥n

Si una soluci√≥n b√°sica factible tiene m√°s de una variable b√°sica igual a cero, se dice que la soluci√≥n es degenerada.

**Implicaci√≥n**: La degeneraci√≥n puede causar ciclos en el m√©todo Simplex, afectando la eficiencia del algoritmo.

**Referencia**: Winston, Operations Research: Applications and Algorithms, 4th ed., p. 168.

## Preguntas y Respuestas Clave en Programaci√≥n Lineal

### Qu√© pasa con el dual si el costo sombra de una variable es 0?
Si el costo sombra de una variable en el primal es 0, esto significa que la restricci√≥n correspondiente en el dual no tiene holgura y no contribuye al valor de la funci√≥n objetivo del dual. Esto puede implicar que la restricci√≥n es redundante en el contexto del problema dual.

### ¬øQu√© pasa si el primal y el dual tienen el mismo valor √≥ptimo?
Seg√∫n el Teorema de Dualidad Fuerte, si ambos, el primal y el dual tienen soluciones √≥ptimas, sus valores √≥ptimos son iguales. Esto implica que las soluciones son viables y que se ha alcanzado la √≥ptima eficiencia de recursos.

### ¬øC√≥mo se hace para saber si un problema tiene m√∫ltiples soluciones?
Un problema de programaci√≥n lineal tiene m√∫ltiples soluciones √≥ptimas si en la √∫ltima iteraci√≥n del m√©todo simplex, una variable no b√°sica tiene un costo reducido de cero. Esto indica que hay una direcci√≥n en la que se puede mover sin cambiar el valor de la funci√≥n objetivo, lo que resulta en m√∫ltiples soluciones √≥ptimas.

### ¬øQu√© pasa con el dual si el costo sombra de una variable es 0?
Si el costo sombra (precio dual) de una variable en el primal es 0, esto significa que la restricci√≥n correspondiente en el dual no tiene holgura (es decir, la restricci√≥n es exactamente una igualdad en la soluci√≥n √≥ptima). Esto implica que el recurso adicional no afecta el valor de la funci√≥n objetivo del dual.

### ¬øQu√© significa el precio sombra de una restricci√≥n?
El precio sombra de una restricci√≥n indica cu√°nto cambiar√° el valor de la funci√≥n objetivo si se incrementa el lado derecho de la restricci√≥n en una unidad, manteniendo todo lo dem√°s constante. En otras palabras, mide la sensibilidad del valor √≥ptimo a cambios en la disponibilidad del recurso correspondiente.

### ¬øC√≥mo afectan los cambios en los valores del RHS a la soluci√≥n √≥ptima?
Los cambios en los valores del RHS afectan la soluci√≥n √≥ptima dentro de ciertos rangos. Si el cambio est√° dentro del rango permisible del RHS, la base √≥ptima no cambiar√°. Si el cambio est√° fuera de este rango, ser√° necesario resolver nuevamente el problema para encontrar la nueva soluci√≥n √≥ptima.

### ¬øQu√© indican los rangos permisibles de los coeficientes de la funci√≥n objetivo?
Los rangos permisibles de los coeficientes de la funci√≥n objetivo indican cu√°nto pueden variar los coeficientes de las variables en la funci√≥n objetivo antes de que la base √≥ptima cambie. Dentro de estos rangos, la soluci√≥n √≥ptima permanece la misma, aunque el valor de la funci√≥n objetivo puede cambiar.

### ¬øQu√© implica la factibilidad del dual para la soluci√≥n del primal?
Si el problema primal tiene una soluci√≥n factible y acotada, el dual tambi√©n tendr√° una soluci√≥n factible y acotada, y viceversa. Si uno de los problemas es no acotado o no tiene soluci√≥n factible, el otro tampoco la tendr√°.

### ¬øQu√© implica la holgura complementaria en soluciones √≥ptimas?
La holgura complementaria establece que en las soluciones √≥ptimas del primal y el dual, el producto de cada variable primal y su correspondiente restricci√≥n dual debe ser cero. Esto significa que si una variable primal es positiva, la restricci√≥n dual correspondiente es una igualdad, y si una restricci√≥n primal tiene holgura, la variable dual correspondiente es cero.

### ¬øQu√© condiciones deben cumplir las soluciones √≥ptimas del primal y el dual seg√∫n las condiciones de optimalidad KKT?
Las condiciones KKT establecen que una soluci√≥n \(x^*\) del primal y \(y^*\) del dual son √≥ptimas si cumplen:
1. **Viabilidad Primal**: \(x^*\) cumple todas las restricciones del primal.
2. **Viabilidad Dual**: \(y^*\) cumple todas las restricciones del dual.
3. **Holgura Complementaria**: \(x_i^* \cdot (Ax - b)_i = 0\) para todas las \(i\).
4. **No Negatividad**: Todas las variables son no negativas en sus respectivos dominios.

### ¬øC√≥mo se determina si se debe introducir una nueva variable (producto) en el modelo?
Para determinar si se debe introducir una nueva variable, se calcula su costo reducido (\(\bar{c}_j\)). Si el costo reducido es negativo en un problema de maximizaci√≥n, o positivo en un problema de minimizaci√≥n, entonces la introducci√≥n de esta variable mejorar√° el valor de la funci√≥n objetivo y debe ser incluida en la soluci√≥n.

### ¬øPara convertir a la forma est√°ndar, el tipo de variabla de holgura (exceso o holgura) depende del tipo de restricci√≥n y de si es minimizaci√≥n o maximizaci√≥n?
No, el tipo de variable de holgura (exceso o holgura) **no** depende de si el problema es de **minimizaci√≥n** o **maximizaci√≥n**. Depende √∫nicamente del tipo de restricci√≥n que se est√© tratando:

- **\(\leq\) ** ‚Üí **Variable de holgura \(s\)** (se suma para convertir la desigualdad en igualdad).
- **\(\geq\) ** ‚Üí **Variable de exceso \(e\)** (se resta para convertir la desigualdad en igualdad).
- **\(=\)** ‚Üí No requiere variables adicionales para convertir a la forma est√°ndar. 

Por lo tanto, la selecci√≥n de una variable de holgura o de exceso es independiente del objetivo del problema (ya sea minimizaci√≥n o maximizaci√≥n) y est√° √∫nicamente determinada por el tipo de desigualdad en las restricciones.


